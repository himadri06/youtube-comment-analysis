{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as himadri06\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as himadri06\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"himadri06/youtube-comment-analysis\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"himadri06/youtube-comment-analysis\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository himadri06/youtube-comment-analysis initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository himadri06/youtube-comment-analysis initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/15 12:42:22 INFO mlflow.tracking.fluent: Experiment with name 'Experiment 5-XGBoost with HPT' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/d73c2880a72c4242aac5898811628197', creation_time=1734246743523, experiment_id='5', last_update_time=1734246743523, lifecycle_stage='active', name='Experiment 5-XGBoost with HPT', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='himadri06', repo_name='youtube-comment-analysis', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/himadri06/youtube-comment-analysis.mlflow\")\n",
    "mlflow.set_experiment(\"Experiment 5-XGBoost with HPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "     -------------------------------------- 364.4/364.4 KB 7.5 MB/s eta 0:00:00\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from optuna) (24.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.9.0 optuna-4.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:/Users/User/Desktop/MLOPs/youtube-comment/youtube-comment-analysis/data/processed/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 12:45:15,651] A new study created in memory with name: no-name-f54c16e0-ca6c-488a-9d97-4431a2eed762\n",
      "[I 2024-12-15 12:46:20,169] Trial 0 finished with value: 0.5336151643256511 and parameters: {'n_estimators': 119, 'learning_rate': 0.0005045634042989749, 'max_depth': 4}. Best is trial 0 with value: 0.5336151643256511.\n",
      "[I 2024-12-15 12:55:08,032] Trial 1 finished with value: 0.5953906995772535 and parameters: {'n_estimators': 209, 'learning_rate': 0.00028341817308463345, 'max_depth': 8}. Best is trial 1 with value: 0.5953906995772535.\n",
      "[I 2024-12-15 13:02:51,884] Trial 2 finished with value: 0.594981590072276 and parameters: {'n_estimators': 185, 'learning_rate': 0.00040375600456170715, 'max_depth': 8}. Best is trial 1 with value: 0.5953906995772535.\n",
      "[I 2024-12-15 13:08:27,831] Trial 3 finished with value: 0.7153961543706532 and parameters: {'n_estimators': 214, 'learning_rate': 0.028374996863528807, 'max_depth': 7}. Best is trial 3 with value: 0.7153961543706532.\n",
      "[I 2024-12-15 13:09:19,466] Trial 4 finished with value: 0.5340242738306287 and parameters: {'n_estimators': 70, 'learning_rate': 0.0007798531766839217, 'max_depth': 4}. Best is trial 3 with value: 0.7153961543706532.\n",
      "[I 2024-12-15 13:18:31,595] Trial 5 finished with value: 0.7344879312696032 and parameters: {'n_estimators': 171, 'learning_rate': 0.032029542644379336, 'max_depth': 10}. Best is trial 5 with value: 0.7344879312696032.\n",
      "[I 2024-12-15 13:20:53,277] Trial 6 finished with value: 0.7395336151643257 and parameters: {'n_estimators': 281, 'learning_rate': 0.07558187800918163, 'max_depth': 3}. Best is trial 6 with value: 0.7395336151643257.\n",
      "[I 2024-12-15 13:23:34,702] Trial 7 finished with value: 0.5877539888176735 and parameters: {'n_estimators': 70, 'learning_rate': 0.00010594418608662515, 'max_depth': 8}. Best is trial 6 with value: 0.7395336151643257.\n",
      "[I 2024-12-15 13:24:47,835] Trial 8 finished with value: 0.5447974907950361 and parameters: {'n_estimators': 88, 'learning_rate': 0.00014558782851027864, 'max_depth': 5}. Best is trial 6 with value: 0.7395336151643257.\n",
      "[I 2024-12-15 13:27:27,800] Trial 9 finished with value: 0.7358516296195282 and parameters: {'n_estimators': 196, 'learning_rate': 0.057651682619455254, 'max_depth': 5}. Best is trial 6 with value: 0.7395336151643257.\n",
      "[I 2024-12-15 13:29:06,475] Trial 10 finished with value: 0.607800354561571 and parameters: {'n_estimators': 285, 'learning_rate': 0.008665237235532601, 'max_depth': 3}. Best is trial 6 with value: 0.7395336151643257.\n",
      "[I 2024-12-15 13:32:31,179] Trial 11 finished with value: 0.7804445656620755 and parameters: {'n_estimators': 300, 'learning_rate': 0.08149642458811, 'max_depth': 5}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 13:34:13,044] Trial 12 finished with value: 0.7460793672439656 and parameters: {'n_estimators': 293, 'learning_rate': 0.08348975817406852, 'max_depth': 3}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 13:39:09,665] Trial 13 finished with value: 0.6394381562798309 and parameters: {'n_estimators': 249, 'learning_rate': 0.00580277214950647, 'max_depth': 6}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 13:41:49,661] Trial 14 finished with value: 0.6642574662484658 and parameters: {'n_estimators': 300, 'learning_rate': 0.014676096578459434, 'max_depth': 4}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 13:46:55,357] Trial 15 finished with value: 0.5926633028774035 and parameters: {'n_estimators': 250, 'learning_rate': 0.001889022703093335, 'max_depth': 6}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 13:48:13,494] Trial 16 finished with value: 0.7448520387290332 and parameters: {'n_estimators': 254, 'learning_rate': 0.0951931627729729, 'max_depth': 3}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 13:50:14,696] Trial 17 finished with value: 0.6564843856538933 and parameters: {'n_estimators': 143, 'learning_rate': 0.01928024383001902, 'max_depth': 5}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 13:52:35,507] Trial 18 finished with value: 0.5672985135687986 and parameters: {'n_estimators': 233, 'learning_rate': 0.002428327406327098, 'max_depth': 4}. Best is trial 11 with value: 0.7804445656620755.\n",
      "[I 2024-12-15 14:01:49,904] Trial 19 finished with value: 0.7839901813718806 and parameters: {'n_estimators': 272, 'learning_rate': 0.051200793873198855, 'max_depth': 10}. Best is trial 19 with value: 0.7839901813718806.\n",
      "[I 2024-12-15 14:16:18,048] Trial 20 finished with value: 0.6690304104732033 and parameters: {'n_estimators': 262, 'learning_rate': 0.005447201162668522, 'max_depth': 10}. Best is trial 19 with value: 0.7839901813718806.\n",
      "[I 2024-12-15 14:24:55,443] Trial 21 finished with value: 0.775944361107323 and parameters: {'n_estimators': 296, 'learning_rate': 0.04190561184002331, 'max_depth': 9}. Best is trial 19 with value: 0.7839901813718806.\n",
      "[I 2024-12-15 14:33:50,526] Trial 22 finished with value: 0.7680349106777581 and parameters: {'n_estimators': 279, 'learning_rate': 0.03978490524600751, 'max_depth': 9}. Best is trial 19 with value: 0.7839901813718806.\n",
      "[I 2024-12-15 14:44:37,520] Trial 23 finished with value: 0.7040774580662758 and parameters: {'n_estimators': 271, 'learning_rate': 0.012890760026347559, 'max_depth': 9}. Best is trial 19 with value: 0.7839901813718806.\n",
      "[I 2024-12-15 14:52:10,758] Trial 24 finished with value: 0.7527614891585981 and parameters: {'n_estimators': 231, 'learning_rate': 0.03635617528383739, 'max_depth': 9}. Best is trial 19 with value: 0.7839901813718806.\n",
      "[I 2024-12-15 15:01:19,126] Trial 25 finished with value: 0.793945179326333 and parameters: {'n_estimators': 299, 'learning_rate': 0.05086509590674834, 'max_depth': 10}. Best is trial 25 with value: 0.793945179326333.\n",
      "[I 2024-12-15 15:11:38,035] Trial 26 finished with value: 0.7133506068457657 and parameters: {'n_estimators': 237, 'learning_rate': 0.016474366948827156, 'max_depth': 10}. Best is trial 25 with value: 0.793945179326333.\n",
      "[I 2024-12-15 15:18:27,041] Trial 27 finished with value: 0.590890495022501 and parameters: {'n_estimators': 272, 'learning_rate': 0.001256567436628196, 'max_depth': 7}. Best is trial 25 with value: 0.793945179326333.\n",
      "[I 2024-12-15 15:47:10,894] Trial 28 finished with value: 0.7567162143733807 and parameters: {'n_estimators': 147, 'learning_rate': 0.055169444874685065, 'max_depth': 10}. Best is trial 25 with value: 0.793945179326333.\n",
      "[I 2024-12-15 15:52:32,502] Trial 29 finished with value: 0.7155325242056457 and parameters: {'n_estimators': 300, 'learning_rate': 0.023687884300615834, 'max_depth': 6}. Best is trial 25 with value: 0.793945179326333.\n",
      "2024/12/15 16:03:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/12/15 16:03:33 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBoost_SMOTE_TFIDF_Trigrams at: https://dagshub.com/himadri06/youtube-comment-analysis.mlflow/#/experiments/5/runs/b41f8b5bed1a48a7822125eae2657e34.\n",
      "2024/12/15 16:03:33 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/himadri06/youtube-comment-analysis.mlflow/#/experiments/5.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
    "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
    "\n",
    "# Step 2: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "ngram_range = (1, 3)  # Trigram setting\n",
    "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Step 4: Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
    "\n",
    "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for XGBoost, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_xgboost, n_trials=30)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
    "\n",
    "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
    "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "# Run the experiment for XGBoost\n",
    "run_optuna_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
